## Redis Caching
###### February 21, 2016

I've just implemented Redis caching of the markdown blog files this Node server reads from the file system. Even though it is overkill for this blog in its current form, I wanted to get it out of the way early. I plan on adding several new features in the coming weeks including: tagging, search, pagination, etc. I felt introducing the caching now would be less of an investment than down the line. Plus, it was fun, and going to the file system to retrieve my blogs every time just felt dirty.

It's dead simple right now -- all it needs to be for a blog with only four entries. If a blog isn't in the cache, the markdown is fetched and the transformed HTML is hashed into Redis by the filename. If found, the fs fetch is skipped and the cache string is used. There is no invalidation or rotation at this point. Some time down the line I'll have to implement a way to rotate entries out. Some kind of LRU-ness or by stats on entries.

    Redis Connected
    - Cache miss on docs/blogs/feb21-2016.md
    - Cache hit on docs/blogs/feb18-2016.md
    - Cache hit on docs/blogs/feb17-2016.md
    - Cache hit on docs/blogs/feb15-2016.md
    Adding blog docs/blogs/feb21-2016.md from fs data
    Adding blog docs/blogs/feb18-2016.md from cache data
    Adding blog docs/blogs/feb17-2016.md from cache data
    Adding blog docs/blogs/feb15-2016.md from cache data

Not sold on caching? I've run some basic tests. Not having to go to the filesystem to fetch four markdown files shaved off 4ms from the 6ms original end-to-end response time. The original response time was already so short, but when I start adding content and features to this blog, or if I experience a higher viewer count (hopefully someday), caching will make a difference.

Still not sold? At IBM, we recently finished an internal hackathon for Hackademy. Our two day prototype consisted of three microservices. The first (harvester) would scrape new messages from slack and drop them into a Cloudant database. The second (refinery) would do some processing on these messages and drop them into a second DB. The third (cellar) would present the processed messages in a UI and serve up an API. These API calls made a DB fetch every time until Redis caching was implemented. Response times went from **700ms** to **60ms**. Impressive. Perhaps I'll write about our hackathon project another day.

And with this long entry comes a need for pagination. Stay tuned.
